{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05913d59-e9de-41ee-8ef4-ffc288015942",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader\n",
    "import torch, torchvision\n",
    "import detectron2\n",
    "import json\n",
    "import ast \n",
    "import tensorboard,os\n",
    "from detectron2.utils.logger import setup_logger\n",
    "\n",
    "setup_logger()\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import wandb\n",
    "import os, json, cv2, random\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor, DefaultTrainer\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.structures import BoxMode\n",
    "from tqdm import tqdm\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54f77166-567f-4e53-87a4-bebed5fcf8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_to_remove = os.listdir('./output/')\n",
    "files_to_remove.remove('metrics.json')\n",
    "for file_to_remove in files_to_remove:\n",
    "    os.remove(f'./output/{file_to_remove}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "886fa83a-c439-4554-8d17-777cee97dfdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./Data.csv\").sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f392a7f-893b-4b55-af75-1a5987b1e741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[187, 211, 217],\n",
       "        [185, 209, 215],\n",
       "        [185, 209, 215],\n",
       "        ...,\n",
       "        [191, 212, 220],\n",
       "        [194, 215, 223],\n",
       "        [195, 216, 224]],\n",
       "\n",
       "       [[187, 211, 217],\n",
       "        [186, 210, 216],\n",
       "        [186, 210, 216],\n",
       "        ...,\n",
       "        [196, 215, 223],\n",
       "        [195, 214, 222],\n",
       "        [195, 214, 222]],\n",
       "\n",
       "       [[190, 212, 218],\n",
       "        [189, 211, 217],\n",
       "        [187, 211, 217],\n",
       "        ...,\n",
       "        [197, 216, 224],\n",
       "        [196, 213, 222],\n",
       "        [197, 214, 223]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 37,  29,  12],\n",
       "        [ 35,  27,  10],\n",
       "        [ 36,  28,  11],\n",
       "        ...,\n",
       "        [ 65,  41,  17],\n",
       "        [ 61,  41,  16],\n",
       "        [ 61,  41,  16]],\n",
       "\n",
       "       [[ 39,  29,  12],\n",
       "        [ 37,  27,  10],\n",
       "        [ 39,  29,  12],\n",
       "        ...,\n",
       "        [ 67,  43,  21],\n",
       "        [ 61,  40,  18],\n",
       "        [ 61,  40,  18]],\n",
       "\n",
       "       [[ 40,  30,  13],\n",
       "        [ 38,  28,  11],\n",
       "        [ 40,  30,  13],\n",
       "        ...,\n",
       "        [ 68,  44,  22],\n",
       "        [ 65,  41,  21],\n",
       "        [ 63,  42,  21]]], dtype=uint8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info = data.iloc[59]\n",
    "img = cv2.imread(f'./Img/{info[\"Path\"]}')\n",
    "height, width = cv2.imread(\"./Img/\" + info[\"Path\"]).shape[:2]\n",
    "xmin, ymin, xmax, ymax = info[\"XMin\"], info[\"YMin\"], info[\"XMax\"], info[\"YMax\"]\n",
    "xmin = round(xmin * width)\n",
    "xmax = round(xmax * width)\n",
    "ymin = round(ymin * height)\n",
    "ymax = round(ymax * height)\n",
    "x = xmin\n",
    "y = ymin\n",
    "w = xmax - xmin\n",
    "h = ymax - ymin\n",
    "x,y,w,h = round(x),round(y),round(w),round(h)\n",
    "cv2.imwrite('./output.png',img)\n",
    "roi=img[y:y+h,x:x+w]\n",
    "cv2.rectangle(img,(x,y),(x+w,y+h),(200,0,0),10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b17e1f90-c8b5-432e-be3a-df122a2fb919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Data\n",
    "def load_data(data=data, test=False):\n",
    "    if test is True:\n",
    "        if \"data.npy\" in os.listdir(\"./\"):\n",
    "            data = np.load(\"./data.npy\", allow_pickle=True)\n",
    "            data = data[:325]\n",
    "            print(len(data))\n",
    "            return data\n",
    "    if \"data.npy\" in os.listdir(\"./\"):\n",
    "        data = np.load(\"./data.npy\", allow_pickle=True)\n",
    "        print(len(data))\n",
    "        return data\n",
    "    new_data = []\n",
    "    for idx in tqdm(range(len(data))):\n",
    "        record = {}\n",
    "        info = data.iloc[idx]\n",
    "        height, width = cv2.imread(\"./Img/\" + info[\"Path\"]).shape[:2]\n",
    "        xmin, ymin, xmax, ymax = info[\"XMin\"], info[\"YMin\"], info[\"XMax\"], info[\"YMax\"]\n",
    "        xmin = round(xmin * width)\n",
    "        xmax = round(xmax * width)\n",
    "        ymin = round(ymin * height)\n",
    "        ymax = round(ymax * height)\n",
    "        record[\"file_name\"] = \"./Img/\" + info[\"Path\"]\n",
    "        record[\"height\"] = height\n",
    "        record[\"width\"] = width\n",
    "        objs = [\n",
    "            {\n",
    "                \"bbox\": [xmin,ymin,xmax,ymax],\n",
    "                \"bbox_mode\": BoxMode.XYXY_ABS,\n",
    "                \"category_id\": 0,\n",
    "            }\n",
    "        ]\n",
    "        record[\"image_id\"] = idx\n",
    "        record[\"annotations\"] = objs\n",
    "        new_data.append(record)\n",
    "    np.random.shuffle(new_data)\n",
    "    np.save(\"data.npy\", new_data)\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb92183d-6ced-44ec-9586-ed3ce8ce9b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config\n",
    "labels = [\"Card\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de01b6ab-0060-4988-bea8-90145f494d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the data\n",
    "DatasetCatalog.register(\"data\", lambda: load_data())\n",
    "MetadataCatalog.get(\"data\").set(thing_classes=labels)\n",
    "metadata = MetadataCatalog.get(\"data\")\n",
    "DatasetCatalog.register(\"test\", lambda: load_data(test=True))\n",
    "MetadataCatalog.get(\"test\").set(thing_classes=labels)\n",
    "metadata_test = MetadataCatalog.get(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6fa0905-7359-47bb-82d1-7e46e01e98f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    \"fast_rcnn_R_50_FPN_1x.yaml\",\n",
    "    \"faster_rcnn_R_50_C4_1x.yaml\",\n",
    "    \"faster_rcnn_R_50_C4_3x.yaml\",\n",
    "    \"faster_rcnn_R_50_DC5_1x.yaml\",\n",
    "    \"faster_rcnn_R_50_DC5_3x.yaml\",\n",
    "    \"retinanet_R_50_FPN_1x.py\",\n",
    "    \"retinanet_R_50_FPN_1x.yaml\",\n",
    "    \"retinanet_R_50_FPN_3x.yaml\",\n",
    "    \"rpn_R_50_C4_1x.yaml\",\n",
    "    \"rpn_R_50_FPN_1x.yaml\"\n",
    "    \"faster_rcnn_R_50_FPN_1x.yaml\",\n",
    "    \"faster_rcnn_R_50_FPN_3x.yaml\",\n",
    "    \"faster_rcnn_R_101_DC5_3x.yaml\",\n",
    "    \"faster_rcnn_R_101_FPN_3x.yaml\",\n",
    "    \"faster_rcnn_X_101_32x8d_FPN_3x.yaml\",\n",
    "]\n",
    "max_iters = [\n",
    "    50,100,125,250,500,1000,2000,2500,5000\n",
    "]\n",
    "base_lrs = [\n",
    "    0.1,0.01,0.001,0.0001,0.00001,0.000001\n",
    "]\n",
    "ims_per_batchs = [\n",
    "    1,2,3,4,5,6,7,8,9,10\n",
    "]\n",
    "batch_size_per_images = [\n",
    "    8,16,32,64,128,256,512\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce211722-cd2a-4392-a22d-e769ae8c5a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_LR = 0.00025\n",
    "MAX_ITER = 500\n",
    "EVAL_PERIOD = 500\n",
    "IMS_PER_BATCH = 2\n",
    "BATCH_SIZE_PER_IMAGE = 128\n",
    "SCORE_THRESH_TEST = 0.625\n",
    "model = f\"COCO-Detection/\" + \"faster_rcnn_X_101_32x8d_FPN_3x.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93b60993-b010-4f8b-a9cc-ce7ff377dcb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a2539e4-017c-4bbd-99bd-439f1712a127",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mranuga-d\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.6 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "2021-10-28 20:45:01.168085: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ranuga-d/Find-Card/runs/3r95n0qd\" target=\"_blank\">test</a></strong> to <a href=\"https://wandb.ai/ranuga-d/Find-Card\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/28 20:45:11 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (6): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (7): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (8): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (9): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (10): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (11): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (12): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (13): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (14): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (15): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (16): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (17): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (18): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (19): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (20): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (21): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (22): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            2048, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "1853\n",
      "\u001b[32m[10/28 20:45:11 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 1853 images left.\n",
      "\u001b[32m[10/28 20:45:11 d2.data.build]: \u001b[0mDistribution of instances among all 1 categories:\n",
      "\u001b[36m|  category  | #instances   |\n",
      "|:----------:|:-------------|\n",
      "|    Card    | 1853         |\n",
      "|            |              |\u001b[0m\n",
      "\u001b[32m[10/28 20:45:11 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[10/28 20:45:11 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[10/28 20:45:11 d2.data.common]: \u001b[0mSerializing 1853 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/28 20:45:11 d2.data.common]: \u001b[0mSerialized dataset takes 0.35 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-28 20:45:11.909777: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (2, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (2,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (4, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "The checkpoint state_dict contains keys that are not used by the model:\n",
      "  \u001b[35mproposal_generator.anchor_generator.cell_anchors.{0, 1, 2, 3, 4}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/28 20:45:15 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/indika/Sync/anaconda3/envs/detectron2/lib/python3.8/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:467.)\n",
      "  return torch.floor_divide(self, other)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/28 20:45:35 d2.utils.events]: \u001b[0m eta: 0:07:35  iter: 19  total_loss: 1.027  loss_cls: 0.6055  loss_box_reg: 0.3171  loss_rpn_cls: 0.02086  loss_rpn_loc: 0.006698  time: 0.9913  data_time: 0.0334  lr: 9.7405e-06  max_mem: 5819M\n",
      "\u001b[32m[10/28 20:45:57 d2.utils.events]: \u001b[0m eta: 0:07:32  iter: 39  total_loss: 0.9201  loss_cls: 0.5126  loss_box_reg: 0.3697  loss_rpn_cls: 0.01318  loss_rpn_loc: 0.007745  time: 1.0443  data_time: 0.0024  lr: 1.9731e-05  max_mem: 5851M\n",
      "\u001b[32m[10/28 20:46:22 d2.utils.events]: \u001b[0m eta: 0:07:27  iter: 59  total_loss: 0.8185  loss_cls: 0.4076  loss_box_reg: 0.3843  loss_rpn_cls: 0.01381  loss_rpn_loc: 0.009916  time: 1.1067  data_time: 0.0025  lr: 2.972e-05  max_mem: 6043M\n",
      "\u001b[32m[10/28 20:46:43 d2.utils.events]: \u001b[0m eta: 0:07:07  iter: 79  total_loss: 0.8034  loss_cls: 0.3462  loss_box_reg: 0.4164  loss_rpn_cls: 0.01552  loss_rpn_loc: 0.005157  time: 1.0902  data_time: 0.0023  lr: 3.9711e-05  max_mem: 6043M\n",
      "\u001b[32m[10/28 20:47:03 d2.utils.events]: \u001b[0m eta: 0:06:38  iter: 99  total_loss: 0.7256  loss_cls: 0.2964  loss_box_reg: 0.3388  loss_rpn_cls: 0.01791  loss_rpn_loc: 0.007841  time: 1.0773  data_time: 0.0025  lr: 4.9701e-05  max_mem: 6043M\n",
      "\u001b[32m[10/28 20:47:25 d2.utils.events]: \u001b[0m eta: 0:06:21  iter: 119  total_loss: 0.6439  loss_cls: 0.2707  loss_box_reg: 0.3031  loss_rpn_cls: 0.05774  loss_rpn_loc: 0.008314  time: 1.0808  data_time: 0.0024  lr: 5.9691e-05  max_mem: 6043M\n",
      "\u001b[32m[10/28 20:47:45 d2.utils.events]: \u001b[0m eta: 0:05:58  iter: 139  total_loss: 0.5783  loss_cls: 0.2444  loss_box_reg: 0.2721  loss_rpn_cls: 0.04228  loss_rpn_loc: 0.006962  time: 1.0706  data_time: 0.0024  lr: 6.9681e-05  max_mem: 6043M\n",
      "\u001b[32m[10/28 20:48:06 d2.utils.events]: \u001b[0m eta: 0:05:35  iter: 159  total_loss: 0.6601  loss_cls: 0.271  loss_box_reg: 0.3846  loss_rpn_cls: 0.02542  loss_rpn_loc: 0.005178  time: 1.0647  data_time: 0.0022  lr: 7.9671e-05  max_mem: 6043M\n",
      "\u001b[32m[10/28 20:48:27 d2.utils.events]: \u001b[0m eta: 0:05:18  iter: 179  total_loss: 0.6067  loss_cls: 0.2109  loss_box_reg: 0.3155  loss_rpn_cls: 0.02479  loss_rpn_loc: 0.006786  time: 1.0660  data_time: 0.0025  lr: 8.966e-05  max_mem: 6043M\n",
      "\u001b[32m[10/28 20:48:48 d2.utils.events]: \u001b[0m eta: 0:04:55  iter: 199  total_loss: 0.5595  loss_cls: 0.2272  loss_box_reg: 0.2799  loss_rpn_cls: 0.01839  loss_rpn_loc: 0.00887  time: 1.0620  data_time: 0.0024  lr: 9.9651e-05  max_mem: 6043M\n",
      "\u001b[32m[10/28 20:49:09 d2.utils.events]: \u001b[0m eta: 0:04:36  iter: 219  total_loss: 0.6638  loss_cls: 0.2634  loss_box_reg: 0.357  loss_rpn_cls: 0.03349  loss_rpn_loc: 0.005262  time: 1.0631  data_time: 0.0023  lr: 0.00010964  max_mem: 6043M\n",
      "\u001b[32m[10/28 20:49:32 d2.utils.events]: \u001b[0m eta: 0:04:19  iter: 239  total_loss: 0.5667  loss_cls: 0.2237  loss_box_reg: 0.3104  loss_rpn_cls: 0.01534  loss_rpn_loc: 0.006358  time: 1.0680  data_time: 0.0025  lr: 0.00011963  max_mem: 6043M\n",
      "\u001b[32m[10/28 20:49:54 d2.utils.events]: \u001b[0m eta: 0:04:00  iter: 259  total_loss: 0.6765  loss_cls: 0.2462  loss_box_reg: 0.4049  loss_rpn_cls: 0.01654  loss_rpn_loc: 0.007126  time: 1.0708  data_time: 0.0023  lr: 0.00012962  max_mem: 6043M\n",
      "\u001b[32m[10/28 20:50:17 d2.utils.events]: \u001b[0m eta: 0:03:40  iter: 279  total_loss: 0.5931  loss_cls: 0.2357  loss_box_reg: 0.329  loss_rpn_cls: 0.0204  loss_rpn_loc: 0.005204  time: 1.0748  data_time: 0.0025  lr: 0.00013961  max_mem: 6043M\n",
      "\u001b[32m[10/28 20:50:39 d2.utils.events]: \u001b[0m eta: 0:03:21  iter: 299  total_loss: 0.5314  loss_cls: 0.2019  loss_box_reg: 0.2783  loss_rpn_cls: 0.02776  loss_rpn_loc: 0.01061  time: 1.0781  data_time: 0.0023  lr: 0.0001496  max_mem: 6043M\n",
      "\u001b[32m[10/28 20:51:01 d2.utils.events]: \u001b[0m eta: 0:03:01  iter: 319  total_loss: 0.5689  loss_cls: 0.202  loss_box_reg: 0.3467  loss_rpn_cls: 0.01604  loss_rpn_loc: 0.00911  time: 1.0805  data_time: 0.0024  lr: 0.00015959  max_mem: 6043M\n",
      "\u001b[32m[10/28 20:51:21 d2.utils.events]: \u001b[0m eta: 0:02:40  iter: 339  total_loss: 0.5651  loss_cls: 0.2102  loss_box_reg: 0.2598  loss_rpn_cls: 0.02903  loss_rpn_loc: 0.00655  time: 1.0739  data_time: 0.0024  lr: 0.00016958  max_mem: 6043M\n",
      "\u001b[32m[10/28 20:51:42 d2.utils.events]: \u001b[0m eta: 0:02:21  iter: 359  total_loss: 0.5074  loss_cls: 0.1819  loss_box_reg: 0.2632  loss_rpn_cls: 0.04216  loss_rpn_loc: 0.006141  time: 1.0745  data_time: 0.0025  lr: 0.00017957  max_mem: 6043M\n",
      "\u001b[32m[10/28 20:52:05 d2.utils.events]: \u001b[0m eta: 0:02:00  iter: 379  total_loss: 0.5502  loss_cls: 0.1994  loss_box_reg: 0.3018  loss_rpn_cls: 0.01821  loss_rpn_loc: 0.006678  time: 1.0760  data_time: 0.0024  lr: 0.00018956  max_mem: 6043M\n",
      "\u001b[32m[10/28 20:52:25 d2.utils.events]: \u001b[0m eta: 0:01:40  iter: 399  total_loss: 0.5073  loss_cls: 0.1769  loss_box_reg: 0.2993  loss_rpn_cls: 0.03037  loss_rpn_loc: 0.005838  time: 1.0730  data_time: 0.0025  lr: 0.00019955  max_mem: 6043M\n",
      "\u001b[32m[10/28 20:52:46 d2.utils.events]: \u001b[0m eta: 0:01:20  iter: 419  total_loss: 0.6065  loss_cls: 0.2212  loss_box_reg: 0.3197  loss_rpn_cls: 0.02384  loss_rpn_loc: 0.008727  time: 1.0730  data_time: 0.0025  lr: 0.00020954  max_mem: 6043M\n",
      "\u001b[32m[10/28 20:53:09 d2.utils.events]: \u001b[0m eta: 0:01:00  iter: 439  total_loss: 0.5382  loss_cls: 0.1905  loss_box_reg: 0.3025  loss_rpn_cls: 0.01687  loss_rpn_loc: 0.006767  time: 1.0755  data_time: 0.0026  lr: 0.00021953  max_mem: 6043M\n",
      "\u001b[32m[10/28 20:53:32 d2.utils.events]: \u001b[0m eta: 0:00:40  iter: 459  total_loss: 0.5109  loss_cls: 0.1776  loss_box_reg: 0.3049  loss_rpn_cls: 0.01481  loss_rpn_loc: 0.006365  time: 1.0779  data_time: 0.0024  lr: 0.00022952  max_mem: 6043M\n",
      "\u001b[32m[10/28 20:53:53 d2.utils.events]: \u001b[0m eta: 0:00:20  iter: 479  total_loss: 0.4763  loss_cls: 0.1737  loss_box_reg: 0.2445  loss_rpn_cls: 0.01547  loss_rpn_loc: 0.004807  time: 1.0779  data_time: 0.0024  lr: 0.00023951  max_mem: 6043M\n",
      "\u001b[32m[10/28 20:54:16 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 499  total_loss: 0.4766  loss_cls: 0.203  loss_box_reg: 0.2043  loss_rpn_cls: 0.02415  loss_rpn_loc: 0.007975  time: 1.0805  data_time: 0.0023  lr: 0.0002495  max_mem: 6043M\n",
      "\u001b[32m[10/28 20:54:16 d2.engine.hooks]: \u001b[0mOverall training speed: 498 iterations in 0:08:58 (1.0806 s / it)\n",
      "\u001b[32m[10/28 20:54:16 d2.engine.hooks]: \u001b[0mTotal training time: 0:08:58 (0:00:00 on hooks)\n",
      "\u001b[32m[10/28 20:54:19 d2.evaluation.coco_evaluation]: \u001b[0m'test' is not registered by `register_coco_instances`. Therefore trying to convert it to COCO format ...\n",
      "\u001b[32m[10/28 20:54:19 d2.data.datasets.coco]: \u001b[0mConverting annotations of dataset 'test' to COCO format ...)\n",
      "325\n",
      "\u001b[32m[10/28 20:54:19 d2.data.datasets.coco]: \u001b[0mConverting dataset dicts into COCO format\n",
      "\u001b[32m[10/28 20:54:19 d2.data.datasets.coco]: \u001b[0mConversion finished, #images: 325, #annotations: 325\n",
      "\u001b[32m[10/28 20:54:19 d2.data.datasets.coco]: \u001b[0mCaching COCO format annotations at './output/test_coco_format.json' ...\n",
      "325\n",
      "\u001b[32m[10/28 20:54:19 d2.data.build]: \u001b[0mDistribution of instances among all 1 categories:\n",
      "\u001b[36m|  category  | #instances   |\n",
      "|:----------:|:-------------|\n",
      "|    Card    | 325          |\n",
      "|            |              |\u001b[0m\n",
      "\u001b[32m[10/28 20:54:19 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/28 20:54:19 d2.data.common]: \u001b[0mSerializing 325 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/28 20:54:19 d2.data.common]: \u001b[0mSerialized dataset takes 0.06 MiB\n",
      "\u001b[32m[10/28 20:54:19 d2.evaluation.evaluator]: \u001b[0mStart inference on 325 batches\n",
      "\u001b[32m[10/28 20:54:22 d2.evaluation.evaluator]: \u001b[0mInference done 11/325. Dataloading: 0.0008 s/iter. Inference: 0.1889 s/iter. Eval: 0.0001 s/iter. Total: 0.1898 s/iter. ETA=0:00:59\n",
      "\u001b[32m[10/28 20:54:27 d2.evaluation.evaluator]: \u001b[0mInference done 37/325. Dataloading: 0.0009 s/iter. Inference: 0.1948 s/iter. Eval: 0.0001 s/iter. Total: 0.1959 s/iter. ETA=0:00:56\n",
      "\u001b[32m[10/28 20:54:32 d2.evaluation.evaluator]: \u001b[0mInference done 63/325. Dataloading: 0.0009 s/iter. Inference: 0.1949 s/iter. Eval: 0.0001 s/iter. Total: 0.1960 s/iter. ETA=0:00:51\n",
      "\u001b[32m[10/28 20:54:37 d2.evaluation.evaluator]: \u001b[0mInference done 88/325. Dataloading: 0.0009 s/iter. Inference: 0.1966 s/iter. Eval: 0.0001 s/iter. Total: 0.1978 s/iter. ETA=0:00:46\n",
      "\u001b[32m[10/28 20:54:42 d2.evaluation.evaluator]: \u001b[0mInference done 114/325. Dataloading: 0.0013 s/iter. Inference: 0.1966 s/iter. Eval: 0.0001 s/iter. Total: 0.1981 s/iter. ETA=0:00:41\n",
      "\u001b[32m[10/28 20:54:47 d2.evaluation.evaluator]: \u001b[0mInference done 141/325. Dataloading: 0.0012 s/iter. Inference: 0.1944 s/iter. Eval: 0.0001 s/iter. Total: 0.1958 s/iter. ETA=0:00:36\n",
      "\u001b[32m[10/28 20:54:52 d2.evaluation.evaluator]: \u001b[0mInference done 166/325. Dataloading: 0.0021 s/iter. Inference: 0.1945 s/iter. Eval: 0.0001 s/iter. Total: 0.1968 s/iter. ETA=0:00:31\n",
      "\u001b[32m[10/28 20:54:57 d2.evaluation.evaluator]: \u001b[0mInference done 192/325. Dataloading: 0.0020 s/iter. Inference: 0.1942 s/iter. Eval: 0.0001 s/iter. Total: 0.1964 s/iter. ETA=0:00:26\n",
      "\u001b[32m[10/28 20:55:02 d2.evaluation.evaluator]: \u001b[0mInference done 216/325. Dataloading: 0.0034 s/iter. Inference: 0.1947 s/iter. Eval: 0.0001 s/iter. Total: 0.1982 s/iter. ETA=0:00:21\n",
      "\u001b[32m[10/28 20:55:07 d2.evaluation.evaluator]: \u001b[0mInference done 241/325. Dataloading: 0.0031 s/iter. Inference: 0.1951 s/iter. Eval: 0.0001 s/iter. Total: 0.1985 s/iter. ETA=0:00:16\n",
      "\u001b[32m[10/28 20:55:13 d2.evaluation.evaluator]: \u001b[0mInference done 267/325. Dataloading: 0.0035 s/iter. Inference: 0.1947 s/iter. Eval: 0.0001 s/iter. Total: 0.1984 s/iter. ETA=0:00:11\n",
      "\u001b[32m[10/28 20:55:18 d2.evaluation.evaluator]: \u001b[0mInference done 294/325. Dataloading: 0.0036 s/iter. Inference: 0.1944 s/iter. Eval: 0.0001 s/iter. Total: 0.1982 s/iter. ETA=0:00:06\n",
      "\u001b[32m[10/28 20:55:23 d2.evaluation.evaluator]: \u001b[0mInference done 321/325. Dataloading: 0.0034 s/iter. Inference: 0.1938 s/iter. Eval: 0.0001 s/iter. Total: 0.1974 s/iter. ETA=0:00:00\n",
      "\u001b[32m[10/28 20:55:24 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:03.229597 (0.197592 s / iter per device, on 1 devices)\n",
      "\u001b[32m[10/28 20:55:24 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:01 (0.193721 s / iter per device, on 1 devices)\n",
      "\u001b[32m[10/28 20:55:24 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/28 20:55:24 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/coco_instances_results.json\n",
      "\u001b[32m[10/28 20:55:24 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/28 20:55:24 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/28 20:55:24 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.03 seconds.\n",
      "\u001b[32m[10/28 20:55:24 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/28 20:55:24 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.00 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.089\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.140\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.103\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.052\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.098\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.193\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.269\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.269\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.103\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.299\n",
      "\u001b[32m[10/28 20:55:24 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
      "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
      "| 8.865 | 13.962 | 10.280 | 0.000 | 5.248 | 9.787 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 26/26 [00:00<00:00, 1749.93it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_566961/115025483.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m589\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./download/Img/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Path\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m \u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./download/Img/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Path\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0mxmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mymin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mymax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"XMin\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"YMin\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"XMax\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"YMax\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0mxmin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxmin\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "files_to_remove = os.listdir(\"./output/\")\n",
    "for file_to_remove in files_to_remove:\n",
    "    os.remove(f\"./output/{file_to_remove}\")\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "torch.cuda.empty_cache()\n",
    "wandb.init(project=\"Find-Card\", name=NAME,config={\n",
    "    'BASE_LR':BASE_LR,\n",
    "    'MAX_ITER':MAX_ITER,\n",
    "    'EVAL_PERIOD':EVAL_PERIOD,\n",
    "    'IMS_PER_BATCH':IMS_PER_BATCH,\n",
    "    'BATCH_SIZE_PER_IMAGE':BATCH_SIZE_PER_IMAGE,\n",
    "    'SCORE_THRESH_TEST':SCORE_THRESH_TEST,\n",
    "    'MODEL':model,\n",
    "    'NAME':NAME\n",
    "})\n",
    "torch.cuda.empty_cache()\n",
    "cfg = get_cfg()\n",
    "torch.cuda.empty_cache()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(model))\n",
    "torch.cuda.empty_cache()\n",
    "cfg.DATASETS.TRAIN = (\"data\",)\n",
    "torch.cuda.empty_cache()\n",
    "cfg.DATASETS.TEST = ()\n",
    "torch.cuda.empty_cache()\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(model)\n",
    "torch.cuda.empty_cache()\n",
    "cfg.SOLVER.MAX_ITER = MAX_ITER\n",
    "torch.cuda.empty_cache()\n",
    "cfg.TEST.EVAL_PERIOD = EVAL_PERIOD\n",
    "cfg.SOLVER.BASE_LR = BASE_LR\n",
    "torch.cuda.empty_cache()\n",
    "cfg.SOLVER.STEPS = []\n",
    "torch.cuda.empty_cache()\n",
    "cfg.SOLVER.IMS_PER_BATCH = IMS_PER_BATCH\n",
    "torch.cuda.empty_cache()\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = len(labels)\n",
    "torch.cuda.empty_cache()\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = BATCH_SIZE_PER_IMAGE\n",
    "torch.cuda.empty_cache()\n",
    "trainer = DefaultTrainer(cfg)\n",
    "torch.cuda.empty_cache()\n",
    "trainer.resume_or_load(resume=False)\n",
    "torch.cuda.empty_cache()\n",
    "trainer.train()\n",
    "torch.cuda.empty_cache()\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = SCORE_THRESH_TEST\n",
    "torch.cuda.empty_cache()\n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
    "torch.cuda.empty_cache()\n",
    "predictor = DefaultPredictor(cfg)\n",
    "torch.cuda.empty_cache()\n",
    "cfg.MODEL.WEIGHTS = \"./output/model_final.pth\"\n",
    "cfg.SOLVER.SCORE_THRESH_TEST = SCORE_THRESH_TEST\n",
    "predictor = DefaultPredictor(cfg)\n",
    "evaluator = COCOEvaluator(\"test\", output_dir=\"./output/\")\n",
    "val_loader = build_detection_test_loader(cfg, \"test\")\n",
    "metrics = inference_on_dataset(predictor.model, val_loader, evaluator)\n",
    "wandb.log(metrics)\n",
    "torch.cuda.empty_cache()\n",
    "logs = open(\"./output/metrics.json\", \"r\").read().split(\"\\n\")\n",
    "for log in tqdm(range(len(logs))):\n",
    "    try:\n",
    "        res = ast.literal_eval(logs[log])\n",
    "        wandb.log(res)\n",
    "    except:\n",
    "        pass\n",
    "for img in os.listdir(\"./test_imgs/\"):\n",
    "    torch.cuda.empty_cache()\n",
    "    v = Visualizer(cv2.imread(f\"./test_imgs/{img}\")[:, :, ::-1], metadata=metadata)\n",
    "    torch.cuda.empty_cache()\n",
    "    v = v.draw_instance_predictions(\n",
    "        predictor(cv2.imread(f\"./test_imgs/{img}\"))[\"instances\"].to(\"cpu\")\n",
    "    )\n",
    "    torch.cuda.empty_cache()\n",
    "    v = v.get_image()[:, :, ::-1]\n",
    "    torch.cuda.empty_cache()\n",
    "    plt.figure(figsize=(24, 12))\n",
    "    torch.cuda.empty_cache()\n",
    "    plt.imshow(v)\n",
    "    torch.cuda.empty_cache()\n",
    "    plt.savefig(f\"./preds/{img}\")\n",
    "    torch.cuda.empty_cache()\n",
    "    plt.close()\n",
    "    torch.cuda.empty_cache()\n",
    "    wandb.log({f\"Img/{img}\": wandb.Image(cv2.imread(f\"./preds/{img}\"))})\n",
    "info = data.iloc[589]\n",
    "img = cv2.imread(\"./download/Img/\" + info[\"Path\"])\n",
    "height, width = cv2.imread(\"./download/Img/\" + info[\"Path\"]).shape[:2]\n",
    "xmin, ymin, xmax, ymax = info[\"XMin\"], info[\"YMin\"], info[\"XMax\"], info[\"YMax\"]\n",
    "xmin = round(xmin * width)\n",
    "xmax = round(xmax * width)\n",
    "ymin = round(ymin * height)\n",
    "ymax = round(ymax * height)\n",
    "x = xmin\n",
    "y = ymin\n",
    "w = xmax - xmin\n",
    "h = ymax - ymin\n",
    "preds = predictor(img)\n",
    "target = torch.tensor([xmin, ymin, xmax, ymax])\n",
    "lowest_rmse = 0\n",
    "r_mean_squared_error = MeanSquaredError(squared=False)\n",
    "preds_new = preds[\"instances\"].__dict__[\"_fields\"][\"pred_boxes\"].__dict__[\"tensor\"]\n",
    "for pred_i in range(len(preds)):\n",
    "    pred = preds_new[pred_i]\n",
    "    if r_mean_squared_error(pred.to(\"cpu\"), target) > lowest_rmse:\n",
    "        lowest_rmse = r_mean_squared_error(pred.to(\"cpu\"), target)\n",
    "lowest_mse = 0\n",
    "mean_squared_error = MeanSquaredError(squared=True)\n",
    "preds_new = preds[\"instances\"].__dict__[\"_fields\"][\"pred_boxes\"].__dict__[\"tensor\"]\n",
    "for pred_i in range(len(preds)):\n",
    "    pred = preds_new[pred_i]\n",
    "    if mean_squared_error(pred.to(\"cpu\"), target) > lowest_mse:\n",
    "        lowest_mse = mean_squared_error(pred.to(\"cpu\"), target)\n",
    "wandb.log({\"MSE\": lowest_mse})\n",
    "wandb.log({\"RMSE\": lowest_rmse})\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "231753a3-3192-414d-96f3-739a28a9d7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics import MeanAbsoluteError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48fc5392-db8d-4493-b967-0a76c378527b",
   "metadata": {},
   "outputs": [],
   "source": [
    "info = data.iloc[589]\n",
    "img = cv2.imread(\"./download/Img/\" + info[\"Path\"])\n",
    "height, width = cv2.imread(\"./download/Img/\" + info[\"Path\"]).shape[:2]\n",
    "xmin, ymin, xmax, ymax = info[\"XMin\"], info[\"YMin\"], info[\"XMax\"], info[\"YMax\"]\n",
    "xmin = round(xmin * width)\n",
    "xmax = round(xmax * width)\n",
    "ymin = round(ymin * height)\n",
    "ymax = round(ymax * height)\n",
    "x = xmin\n",
    "y = ymin\n",
    "w = xmax - xmin\n",
    "h = ymax - ymin\n",
    "preds = predictor(img)\n",
    "target = torch.tensor([xmin, ymin, xmax, ymax])\n",
    "lowest_rmse = 0\n",
    "r_mean_squared_error = MeanSquaredError(squared=False)\n",
    "preds_new = preds[\"instances\"].__dict__[\"_fields\"][\"pred_boxes\"].__dict__[\"tensor\"]\n",
    "for pred_i in range(len(preds)):\n",
    "    pred = preds_new[pred_i]\n",
    "    if r_mean_squared_error(pred.to(\"cpu\"), target) > lowest_rmse:\n",
    "        lowest_rmse = r_mean_squared_error(pred.to(\"cpu\"), target)\n",
    "lowest_mse = 0\n",
    "mean_squared_error = MeanSquaredError(squared=True)\n",
    "preds_new = preds[\"instances\"].__dict__[\"_fields\"][\"pred_boxes\"].__dict__[\"tensor\"]\n",
    "for pred_i in range(len(preds)):\n",
    "    pred = preds_new[pred_i]\n",
    "    if mean_squared_error(pred.to(\"cpu\"), target) > lowest_mse:\n",
    "        lowest_mse = mean_squared_error(pred.to(\"cpu\"), target)\n",
    "wandb.log({\"MSE\": lowest_mse})\n",
    "wandb.log({\"RMSE\": lowest_rmse})\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "95809b5d-b53f-4d51-8248-5106c8c3ba19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'625.png'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info['Path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c24e0a3-96fa-424f-9741-a188f5f96532",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(cfg,f'./models/cfg-{NAME}.pt')\n",
    "torch.save(cfg,f'./models/cfg-{NAME}.pth')\n",
    "torch.save(predictor,f'./models/predictor-{NAME}.pt')\n",
    "torch.save(predictor,f'./models/predictor-{NAME}.pth')\n",
    "torch.save(evaluator,f'./models/evaluator-{NAME}.pt')\n",
    "torch.save(evaluator,f'./models/evaluator-{NAME}.pth')\n",
    "torch.save(model,f'./models/model-{NAME}.pt')\n",
    "torch.save(model,f'./models/model-{NAME}.pth')\n",
    "torch.save(labels,f'./models/labels-{NAME}.pt')\n",
    "torch.save(labels,f'./models/labels-{NAME}.pth')\n",
    "torch.save(metrics,f'./models/metrics-{NAME}.pt')\n",
    "torch.save(metrics,f'./models/metrics-{NAME}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd76b61b-ac9c-418f-8462-6b1deee60162",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('detectron2': conda)",
   "language": "python",
   "name": "python3812jvsc74a57bd0585e9a5027b519a27e411109b09a66bc779a1bba36bd86b08fdb64645f8a2c5a"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
